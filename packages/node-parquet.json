{"name":"node-parquet","version":"0.2.4","description":"Parquet is a columnar storage format","main":"index.js","scripts":{"preinstall":"./build_parquet-cpp.sh","install":"node-gyp rebuild","clean":"rm -rf build_deps","test":"tap test/*.js"},"bin":{"parquet":"./bin/parquet.js"},"repository":"https://github.com/skale-me/node-parquet","keywords":["big data","parquet","skale","ETL"],"license":"Apache-2.0","dependencies":{"hexdump-nodejs":"^0.1.0","minimist":"^1.2.0","nan":"^2.5.0","varint":"^5.0.0"},"devDependencies":{"tap":"^10.3.0"},"gitHead":"4bc161774459718264fc044e5b07e8fab4afb617","homepage":"https://github.com/skale-me/node-parquet#readme","versions":[{"number":"0.1.0","date":"2017-02-10T14:37:05.085Z"},{"number":"0.1.1","date":"2017-02-10T15:35:45.527Z"},{"number":"0.2.0","date":"2017-03-07T21:31:43.223Z"},{"number":"0.2.1","date":"2017-03-08T10:09:56.052Z"},{"number":"0.2.2","date":"2017-03-08T21:55:53.689Z"},{"number":"0.2.3","date":"2017-03-10T07:43:42.822Z"},{"number":"0.2.4","date":"2017-04-04T07:34:25.235Z"}],"readme":"# Node-parquet\n\n[![Build Status](https://travis-ci.org/mvertes/node-parquet.svg?branch=master)](https://travis-ci.org/mvertes/node-parquet)\n\n[Parquet](http://parquet.apache.org) is a [columnar\nstorage](https://en.wikipedia.org/wiki/Column-oriented_DBMS) format\navailable to any project in the Hadoop ecosystem. This nodejs module\nprovides native bindings to the parquet functions from\n[parquet-cpp](https://github.com/apache/parquet-cpp).\n\nA pure javascript parquet format driver (still in development) is also provided.\n\n## Build, install\n\nThe native c++ module has the following dependencies which must\nbe installed before attempting to build:\n\n- g++ and gcc version >= 4.8\n- cmake > 2.8.6\n- boost\n- on MacOSX: thrift version >= 0.7\n\nNote that you need also python2 and c++/make toolchain for building\nNodeJS native addons.\n\nThe standard way of building and installing, provided that above\ndepencies are met, is simply to run:\n\n```shell\nnpm install\n```\n\nFrom 0.2.4 version, a command line tool called `parquet` is provided.\nIt can be installed globally by running `npm install -g`. Note that\nif you install node-parquet this way, you can still use it as a dependency\nmodule in your local projects by linking (`npm link node-parquet`) which\navoids the cost of recompiling the complete parquet-cpp library and\nits dependencies.\n\nOtherwise, for developers to build directly from a github clone:\n\n```shell\ngit clone https://github.com/mvertes/node-parquet.git\ncd node-parquet\ngit submodule update --init --recursive\nnpm install [-g]\n```\n\nAfter install, the parquet-cpp build directory `build_deps` can be\nremoved by running `npm run clean`, recovering all disk space taken\nfor building parquet-cpp and its dependencies.\n\n## Usage\n\n### Command line tool\n\nA command line tool `parquet` is provided. It's quite minimalist\nright now and needs to be improved:\n\n```\nUsage: parquet [options] <command> [<args>]\n\nCommand line tool to manipulate parquet files\n\nCommands:\n  cat file       Print file content on standard output\n  head file      Print the first lines of file\n  info file      Print file metadata\n\nOptions:\n  -h,--help      Print this help text\n  -V,--version   Print version and exits\n```\n\n### Reading\n\nThe following example shows how to read a `parquet` file:\n\n```javascript\nvar parquet = require('node-parqet');\n\nvar reader = new parquet.ParquetReader('my_file.parquet');\nconsole.log(reader.info());\nconsole.log(reader.rows();\nreader.close();\n```\n\n### Writing\n\nThe following example shows how to write a `parquet` file:\n\n```javascript\nvar parquet = require('node-parquet');\n\nvar schema = {\n  small_int: {type: 'int32', optional: true},\n  big_int: {type: 'int64'},\n  my_boolean: {type: 'bool'},\n  name: {type: 'byte_array', optional: true},\n};\n\nvar data = [\n  [ 1, 23234, true, 'hello world'],\n  [  , 1234, false, ],\n];\n\nvar writer = new parquet.ParquetWriter('my_file.parquet', schema);\nwriter.write(data);\nwriter.close();\n```\n\n## API reference\n\nThe API is not yet considered stable nor complete.\n\nTo use this module, one must `require('node-parquet')`\n\n### Class: parquet.ParquetReader\n\n`ParquetReader` object performs read operations on a file in parquet format.\n\n#### new parquet.ParquetReader(filename)\n\nConstruct a new parquet reader object.\n\n* `filename`: `String` containing the parquet file path\n\nExample:\n\n```javascript\nconst parquet = require('node-parquet');\nconst reader = new parquet.ParquetReader('./parquet_cpp_example.parquet');\n```\n\n#### reader.close()\n\nClose the reader object.\n\n#### reader.info()\n\nReturn an `Object` containing parquet file metadata. The object looks like:\n\n```javascript\n{\n  version: 0,\n  createdBy: 'Apache parquet-cpp',\n  rowGroups: 1,\n  columns: 8,\n  rows: 500\n}\n```\n\n#### reader.read(column_number)\n\nThis is a low level function, it should not be used directly.\n\nRead and return the next element in the column indicated by `column_number`.\n\nIn the case of a non-nested column, a basic value (`Boolean`, `Number`, `String` or `Buffer`) is returned, otherwise, an array of 3 elemnents is returned, where a[0] is the parquet definition level, a[1] the parquet repetition level, and a[2] the basic value. Definition and repetition levels are useful to reconstruct rows of composite, possibly sparse records with nested columns.\n\n* `column_number`: the column number in the row\n\n#### reader.rows([nb_rows])\n\nReturn an `Array` of rows, where each row is itself an `Array` of column elements.\n\n* `nb_rows`: `Number` defining the maximum number of rows to return.\n\n### Class: parquet.ParquetWriter\n\n`ParquetWriter` object implements write operation on a parquet file.\n\n#### new parquet.ParquetWriter(filename, schema, [compression])\n\nConstruct a new parquet writer object.\n\n* `filename`: `String` containing the parquet file path\n* `schema`: `Object` defining the data structure, where keys are column names and values are `Objects` with the following fields:\n  * `\"type\"`: required `String` indicating the type of column data, can be any of:\n      - `\"bool\"`: boolean value, converted from `Boolean`\n      - `\"int32\"`: 32 bits integer value, converted from `Number`\n      - `\"int64\"`: 64 bits integer value, converted from `Number`\n      - `\"float\"`: 32 bits floating number value, converted from `Number`\n      - `\"double\"`: 64 bits floating number value, converted from `Number`\n      - `\"byte_array\"`: array of bytes, converted from a `String`\n      - `\"group\"`: array of nested structures, described with a `\"schema\"` field\n  * `\"optional\"`: `Boolean` indicating if the field can be omitted in a record. Default: `false`.\n  * `\"repeated\"`: `Boolean` indicating if the field can be repeated in a record, thus forming an array. Ignored if not defined within a schema of type `\"group\"` (schema itself or one of its parent).\n  * `\"schema\"`: `Object` which content is a `schema` defining the nested structure. Required for objects where type is `\"group\"`, ignored for others.\n* `compression`: optional `String` indicating the compression algorithm to apply to columns. Can be one of `\"snappy\"`, `\"gzip\"`, `\"brotli\"` or `\"lzo\"`. By default compression is disabled.\n\nFor example, considering the following object: `{ name: \"foo\", content: [ 1, 2, 3] }`, its descriptor schema is:\n\n```javascript\nconst schema = {\n  name: { type: \"byte_array\" },\n  content: {\n    type: \"group\",\n    repeated: \"true\",\n    schema: { i0: { type: \"int32\" } }\n  }\n};\n```\n\n#### writer.close()\n\nClose a file opened for writing. Calling this method explicitely before exiting is mandatory to ensure that memory content is correctly written in the file.\n\n#### writer.writeSync(rows)\n\nWrite the content of `rows` in the file opened by the writer. Data from rows will be dispatched into the separate parquet columns according to the schema specified in the contructor.\n\n* `rows`: `Array` of rows, where each row is itself an `Array` of column elements, according to the schema.\n\nFor example, considering the above nested schema, a write operation could be:\n\n```javascript\nwriter.write([\n  [ \"foo\", [ 1, 2, 3] ],\n  [ \"bar\", [ 100, 400, 600, 2 ] ]\n]);\n```\n\n## Caveats and limitations\n\n- no schema extract at reading yet\n- int64 bigger than 2^53 - 1 are not accaturately represented (big number library like [bignum](https://www.npmjs.com/package/bignum) integration planned)\n- purejs implementation not complete, although most of metadata is now correctly parsed.\n- read and write are only synchronous\n- the native library parquet-cpp does not build on MS-Windows\n- many tests are missing\n- benchmarks are missing\n- neat commmand line tool missing (one provided since 0.2.4)\n\nPlan is to improve this over time. Contributions are welcome.\n\n## License\n\n[Apache-2.0](LICENSE)\n","starsCount":1,"created":"2017-02-10T14:37:05.085Z","modified":"2017-04-04T07:34:25.235Z","lastPublisher":{"name":"mvertes","email":"mvertes@free.fr"},"owners":[{"name":"mvertes","email":"mvertes@free.fr"}],"other":{"_attachments":{},"_from":".","_id":"node-parquet","_nodeVersion":"7.8.0","_npmOperationalInternal":{"host":"packages-18-east.internal.npmjs.com","tmp":"tmp/node-parquet-0.2.4.tgz_1491291264462_0.49204146955162287"},"_npmUser":{"name":"mvertes","email":"mvertes@free.fr"},"_npmVersion":"4.2.0","_rev":"8-7e6b1e600e394e64e7c1404c29a70e48","_shasum":"24881ebe6e3b67aae19b62ed17935bdb3982944e","author":{"name":"Skale team"},"bugs":{"url":"https://github.com/skale-me/node-parquet/issues"},"directories":{},"dist-tags":{"latest":"0.2.4"},"dist":{"shasum":"24881ebe6e3b67aae19b62ed17935bdb3982944e","tarball":"https://registry.npmjs.org/node-parquet/-/node-parquet-0.2.4.tgz"},"maintainers":[{"name":"mvertes","email":"mvertes@free.fr"}],"readmeFilename":"README.md","time":{"modified":"2017-04-04T07:34:25.235Z","created":"2017-02-10T14:37:05.085Z","0.1.0":"2017-02-10T14:37:05.085Z","0.1.1":"2017-02-10T15:35:45.527Z","0.2.0":"2017-03-07T21:31:43.223Z","0.2.1":"2017-03-08T10:09:56.052Z","0.2.2":"2017-03-08T21:55:53.689Z","0.2.3":"2017-03-10T07:43:42.822Z","0.2.4":"2017-04-04T07:34:25.235Z"},"users":{"mvertes":true}}}
{"version":"0.57.0","name":"backendjs","description":"A platform for building backends","main":"index","homepage":"http://bkjs.io","repository":"https://github.com/vseryakov/backendjs","dependencies":{"apn":">= 2.0.0","uuid":">= 2.0.1","cron":">= 1.1.0","express":">= 4.13.4","emailjs":">= 1.0.1","xml2json":">= 0.9.0","mime":">= 1.3.4","marked":">= 0.3.5","http-proxy":">= 1.12.1","hiredis":">= 0.4.1","redis":">= 2.4.2","qs":">= 2.2.2","ejs":">= 1.0.0","passport":">= 0.2.0","ws":">= 1.0.1","formidable":">= 1.0.17","consolidate":">= 0.14.0","cookie-parser":">= 1.4.1","cookie-session":">= 1.0.1","serve-static":">= 1.10.2","nan":">= 2.4.0","bkjs-utils":">= 0.2.2","bkjs-cache":">= 0.5.1","bkjs-sqlite":">= 0.2.0","bkjs-syslog":">= 0.3.0","bkjs-wand":">= 0.5.0"},"modulesDependencies":{"memcached":">= 2.1.1","mongodb":">= 2.1.4","amqp":">= 0.2.4","hazelcast-client":">= 0.5.0","cassandra-driver":">= 3.0.0"},"keywords":["bkjs","webservice","aws","database","API","DynamoDB","Cassandra","Sqlite","PostgreSQL","MySQL","Redis","pubsub","account","location","messaging","instance","jobs","cron","geohash"],"engines":{"node":">=4.0"},"license":"BSD-3-Clause","bin":{"bkjs":"./bkjs","bksh":"./bkjs"},"scripts":{"start":"./bkjs run-backend","stop":"./bkjs stop"},"gitHead":"fc1dc09fbd922656a1cdb7d73c7579e4b93bab14","versions":[{"number":"0.9.0","date":"2014-04-06T20:45:18.752Z"},{"number":"0.9.1","date":"2014-04-13T04:51:24.923Z"},{"number":"0.9.2","date":"2014-04-24T20:16:38.870Z"},{"number":"0.9.3","date":"2014-04-25T02:26:35.721Z"},{"number":"0.9.4","date":"2014-04-28T23:00:44.817Z"},{"number":"0.9.5","date":"2014-05-05T20:04:29.553Z"},{"number":"0.9.6","date":"2014-05-08T04:45:07.926Z"},{"number":"0.9.7","date":"2014-05-13T16:51:02.645Z"},{"number":"0.9.8","date":"2014-05-28T05:33:41.203Z"},{"number":"0.9.9","date":"2014-06-07T03:25:03.204Z"},{"number":"0.9.10","date":"2014-06-29T03:49:16.276Z"},{"number":"0.9.11","date":"2014-07-12T07:33:00.001Z"},{"number":"0.9.13","date":"2014-09-08T04:43:17.263Z"},{"number":"0.9.15","date":"2014-10-11T12:36:04.861Z"},{"number":"0.9.16","date":"2014-10-23T00:32:03.836Z"},{"number":"0.9.17","date":"2014-11-28T02:29:52.825Z"},{"number":"0.12.0","date":"2015-03-28T20:53:13.750Z"},{"number":"0.13.0","date":"2015-05-11T02:37:23.941Z"},{"number":"0.14.1","date":"2015-07-31T00:56:46.089Z"},{"number":"0.25.1","date":"2016-03-09T19:25:44.473Z"},{"number":"0.55.0","date":"2017-04-27T04:13:10.534Z"},{"number":"0.57.0","date":"2017-07-25T03:06:13.896Z"}],"readme":"# Backend platform for node.js\n\nGeneral purpose backend framework. The primary goal is to have a scalable platform for running and managing node.js\nservers for Web services implementation.\n\nThis framework only covers the lower portion of the Web services system:\nnode.js processes, HTTP servers, basic API functinality, database access, caching, messaging between processes,\nmetrics and monitoring, a library of tools for developing node.js servers.\n\nFor the UI and presentation layer there are no restrictions what to use as long as it can run on top of the Express server.\n\nFeatures:\n\n* Exposes a set of Web service APIs over HTTP(S) using Express framework.\n* Database API supports Sqlite, PostgreSQL, MySQL, DynamoDB, Cassandra, MongoDB, Redis with all basic operations behaving the\n  same way allowing to switch databases without changing the code.\n* Database drivers for LevelDB, LMDB, CouchDB, Riak, ElasticSearch support only a subset of all database operations\n* Easily extendable to support any kind of database, provides a database driver on top of Redis with all supported methods.\n* Provides accounts, connections, locations, messaging and icons APIs with basic functionality for a qucik start.\n* Supports crontab and queue job processing by seperate workers.\n* Authentication is based on signed requests using API key and secret, similar to Amazon AWS signing requests.\n* Runs web server as separate processes to utilize multiple CPU cores.\n* Supports WebSockets connections and process them with the same Express routes as HTTP requests\n* Supports several cache modes(Redis, Memcache, Hazelcast, LRU) for the database operations, multiple hosts support\n  in the clients for failover.\n* Supports several PUB/SUB modes of operations using Redis, RabbitMQ, Hazelcast.\n* Supports async jobs processing using several work queue implementations on top of SQS, Redis, DB, RabbitMQ, Hazelcast.\n* Supports common database operations (Get, Put, Del, Update, Select) for all databases using the same DB API.\n* ImageMagick is compiled as C++ module for in-process image scaling.\n* REPL(command line) interface for debugging and looking into server internals.\n* Geohash based location searches supported by all databases drivers.\n* Supports push notifications for mobile devices, APN and GCM/FCM.\n* Supports HTTP(S) reverse proxy mode where multiple Web workers are load-balanced by the proxy\n  server running in the master process instead of relying on the OS scheduling between processes listening on the same port.\n* Can be used with any MVC, MVVC or other types of frameworks that work on top or with the Express server.\n* AWS supports is very well integrated including EC2, S3, DynamoDB, SQS and more.\n* Includes simple log watcher to monitor the log files including system errors.\n* Supports i18n hooks for request/response objects, easily overriden with any real i18n implementation.\n* Integrated very light unit testing facility which can be used to test modules and API requests\n* Support runtime metrics about the timing on database, requests, cache, memory and request rate limit control\n* Hosted on [github](https://github.com/vseryakov/backendjs), BSD licensed.\n\nCheck out the [Documentation](http://bkjs.io) for more details.\n\n# Installation\n\nTo install the module with all optional dependencies if they are available in the system\n\n    npm install backendjs\n\nThis may take some time because of downloading and compiling required dependencies like ImageMagick. They are not required in all\napplications but still part of the core of the system to be available once needed.\n\nTo install from the git\n\n     npm install git+https://github.com/vseryakov/backendjs.git\n\nor simply\n\n     npm install vseryakov/backendjs\n\n# Quick start\n\n* Simplest way of using the backendjs, it will start the server listening on port 8000\n\n        $ node\n        > var bkjs = require('backendjs')\n        > bkjs.server.start()\n\n* Access is allowed only with valid signature except urls that are exlicitely allowed without it (see `api-allow` config parameter below)\n* Same but using the helper tool, by default it will use embedded Sqlite database and listen on port 8000.\n\n        bkjs run\n\n* To start the server and connect to the DynamoDB (command line parameters can be saved in the `etc/config file`, see below about config files)\n\n        bkjs run -db-pool dynamodb -db-dynamodb-pool default -aws-key XXXX -aws-secret XXXX\n\n* If running on EC2 instance with IAM profile then no need to specify AWS credentials:\n\n        bkjs run -db-pool dynamodb -db-dynamodb-pool default\n\n* or to the PostgreSQL server, database backend\n\n        bkjs run -db-pool pgsql -db-pgsql-pool postgresql://postgres@127.0.0.1/backend\n\n* All commands above will behave exactly the same\n\n* **Tables are not created by default**, in order to initialize the database, run the server or the shell with `-db-create-tables` flag,\n  it is called only inside a master process, a worker never creates tables on start\n\n  - prepare the tables in the shell\n\n        bksh -db-pool pgsql -db-pgsql-pool postgresql://postgres@127.0.0.1/backend -db-create-tables\n\n  - run the server and create table son start\n\n        bkjs run -db-pool pgsql -db-pgsql-pool postgresql://postgres@127.0.0.1/backend -db-create-tables\n\n* While the local backendjs is runnning, the documentation is always available at http://localhost:8000/doc.html (or whatever port is the server using)\n\n* By default no external modules are loaded so it needs the accounts module with a\n  parameter `-allow-modules PATTERN`, this will load all modules that match the pattern, default modules start with `bk_`:\n\n        bkjs run -allow-modules bk_\n\n* Go to http://localhost:8000/api.html for the Web console to test API requests.\n  For this example let's create an account.\n\n* Type and execute the following URLs in the Web console:\n\n        /account/add?name=test1&secret=test1&login=test1@test.com\n\n* Now login with the new account, click on *Login* at the top-right corner and enter 'test1' as login and 'test1' as secret in the login popup dialog.\n* If no error message appeared after the login, try to get your current account details:\n\n        /account/get\n\n* Shutdown the backend by pressing Ctrl-C\n* To make your own custom Web app, create a new directory (somewhere else) to store your project and run the following command from that directory:\n\n        bkjs init-app\n\n* The `app.js` file is created in your project directory with 2 additional API endpoints `/test/add` and `/test/[0-9]` to show the simplest way\n  of adding new tables and API commands.\n* The `app.sh` script is created for convenience in the development process, it specifies common arguments and can be customized as needed.\n* Run your new application now, it will start the Web server on port 8000:\n\n        ./app.sh\n\n* Go to http://localhost:8000/api.html and issue command `/test/add?id=1&name=1` and then `/test/1` commands in the console to see it in action\n* Any change in the source files will make the server restart automatically letting you focus on the source code and not server management, this mode\n  is only enabled by default in development mode, check `app.sh` for parameters before running it in the production.\n\n* To start node.js shell with backendjs loaded and initialized, all command line parameters apply to the shell as well\n\n        ./app.sh -shell\n\n* To access the database while in the shell\n\n        > db.select(\"bk_account\", {}, function(err, rows, info) { console.log(err, rows) });\n        > db.select(\"bk_account\", {}, lib.log);\n        > db.add(\"bk_account\", { login: 'test2', secret: 'test2', name' Test 2 name', gender: 'f' }, lib.log);\n        > db.select(\"bk_account\", { gender: 'm' }, lib.log);\n\n* To add users from the command line\n\n        bksh -account-add login test secret test name TestUser email test@test.com\n\n* To see current metrics run the command in the console '/system/stats/get'\n\n* To see charts about accumulated metrics go to http://localhost:8000/metrics.html\n\n# Configuration\n\nAlmost everything in the backend is configurable using a config files, config database or DNS.\nThe whole principle behind it that once deployed in production, even quick restart are impossible to do so\nthere should be a way to push config changes to the processes without restarting.\n\nEvery module defines a set of config parameters that defines the behavior of the code, due to single threaded\nnature of the node.js, it is simple to update any config parameter to a new value so the code can operate differently.\nTo achieve this the code must be written in a special way, like driven by configuration which can be changed at\nany time.\n\nAll configuration goes through the configuration process that checks all inputs and produces valid output which\nis applied to the module variables. Config file or database table with configuration can be loaded on demand or\nperiodically, for example all local config files are watched for modification and reloaded automaticlaly, the\nconfig database is loaded periodically which is defined by another config parameter.\n\n# Backend runtime\n\nWhen the backendjs server starts it spawns several processes that perform different tasks.\n\nThere are 2 major tasks of the backend that can be run at the same time or in any combination:\n- a Web server (server) with Web workers (web)\n- a job scheduler (master)\n\nThese features can be run standalone or under the guard of the monitor which tracks all running processes and restarted any failed ones.\n\nThis is the typical output from the ps command on Linux server:\n\n    ec2-user    891  0.0  0.6 1071632 49504 ?  Ssl  14:33   0:01 bkjs: monitor\n    ec2-user    899  0.0  0.6 1073844 52892 ?  Sl   14:33   0:01 bkjs: master\n    ec2-user    908  0.0  0.8 1081020 68780 ?  Sl   14:33   0:02 bkjs: server\n    ec2-user    917  0.0  0.7 1072820 59008 ?  Sl   14:33   0:01 bkjs: web\n    ec2-user    919  0.0  0.7 1072820 60792 ?  Sl   14:33   0:02 bkjs: web\n    ec2-user    921  0.0  0.7 1072120 40721 ?  Sl   14:33   0:02 bkjs: worker\n\nTo enable any task a command line parameter must be provided, it cannot be specified in the config file. The `bkjs` utility supports several\ncommands that simplify running the backend in different modes.\n\n- `bkjs start` - this command is supposed to be run at the server startup as a service, it runs in the backgroud and the monitors all tasks,\n   the env variable `BKJS_SERVER` can be set in the profile to one of the `master or monitor` to define which run mode to use, default mode is monitor\n- `bkjs run-monitor` - this command is supposed to be run at the server startup, it runs in the backgroud and the monitors all processes,\n   the command line parameters are: `-daemon -monitor -master -syslog`\n- `bkjs run-master` - this command is supposed to be run at the server startup, it runs in the backgroud and the monitors all processes,\n   the command line parameters are: `-daemon -monitor -master -syslog`\n- `bkjs run-watcher` - runs the master and Web server in wather mode checking all source files for changes, this is the common command to be used\n   in development, it passes the command line switches: `-watch -master`\n- `bkjs run` - this command runs without other parameters, all aditional parameters can be added in the command line, this command\n   is a barebone helper to be used with any other custom settings.\n- `bkjs run-shell` or `bksh` - start backendjs shell, no API or Web server is initialized, only the database pools\n\n\n# Application structure\n\nThe main puspose of the backendjs is to provide API to access the data, the data can be stored in the database or some other way\nbut the access to that data will be over HTTP and returned back as JSON. This is default functionality but any custom application\nmay return data in whatever format is required.\n\nBasically the backendjs is a Web server with ability to perform data processing using local or remote jobs which can be scheduled similar to Unix cron.\n\nThe principle behind the system is that nowadays the API services just return data which Web apps or mobiles apps can render to\nthe user without the backend involved. It does not mean this is simple gateway between the database, in many cases it is but if special\nprocessing of the data is needed before sending it to the user, it is possible to do and backendjs provides many convenient helpers and tools for it.\n\nWhen the API layer is initialized, the api module contains `app` object which is an Express server.\n\nSpecial module/namespace `app` is designated to be used for application development/extension. This module is available the same way as the `api` or `core`\nwhich makes it easy to refer and extend with additional methods and structures.\n\nThe typical structure of a backendjs application is the following (created by the bkjs init-app command):\n\n```javascript\n    var bkjs = require('backendjs');\n    var api = bkjs.api;\n    var app = bkjs.app;\n    var db = bkjs.db;\n\n    app.listArg = [];\n\n    // Define the module config parameters\n    core.describeArgs('app', [\n        { name: \"list-arg\", array: 1, type: \"list\", descr: \"List of words\" },\n        { name: \"int-arg\", type: \"int\", descr: \"An integer parameter\" },\n     ]);\n\n    // Describe the tables or data models, all DB pools will use it, the master or shell\n    // process only creates new tables, workers just use the existing tables\n    db.describeTables({\n         ...\n    });\n\n     // Optionally customize the Express environment, setup MVC routes or else, `api.app` is the Express server\n    app.configureMiddleware = function(options, callback)\n    {\n       ...\n       callback()\n    }\n\n    // Register API endpoints, i.e. url callbacks\n    app.configureWeb = function(options, callback)\n    {\n        api.app.get('/some/api/endpoint', function(req, res) {\n          // to return an error, the message will be translated with internal i18n module if locales\n          // are loaded and the request requires it\n          api.sendReply(res, err);\n          // or with custom status and message, explicitely translated\n          api.sendReply(res, 404, res.__(\"not found\"));\n\n          // with config check\n          if (app.intArg > 5) ...\n          if (app.listArg.indexOf(req.query.name) > -1) ...\n\n          // to send data back with optional postprocessing hooks\n          api.sendJSON(req, err, data);\n          // or simply\n          res.json(data);\n        });\n        ...\n        callback();\n    }\n\n    // Optionally register post processing of the returned data from the default calls\n    api.registerPostProcess('', /^\\/account\\/([a-z\\/]+)$/, function(req, res, rows) { ... });\n     ...\n\n    // Optionally register access permissions callbacks\n    api.registerAccessCheck('', /^\\/test\\/list$/, function(req, status, callback) { ...  });\n    api.registerPreProcess('', /^\\/test\\/list$/, function(req, status, callback) { ...  });\n     ...\n    bkjs.server.start();\n```\n\nExcept the `app.configureWeb` and `server.start()` all other functions are optional, they are here for the sake of completness of the example. Also\nbecause running the backend involves more than just running web server many things can be setup using the configuration options like common access permissions,\nconfiguration of the cron jobs so the amount of code to be written to have fully functionaning production API server is not that much, basically only\nrequest endpoint callbacks must be provided in the application.\n\nAs with any node.js application, node modules are the way to build and extend the functionality, backendjs does not restrict how\nthe application is structured.\n\n## Modules\n\nAnother way to add functionality to the backend is via external modules specific to the backend, these modules are loaded on startup from the backend\nhome subdirectory `modules/` and from the backendjs package directory for core modules. The format is the same as for regular node.js modules and\nonly top level .js files are loaded on the backend startup.\n\n*By default no modules are loaded except `bk_accounts|bk_icons`, it must be configured by the `-allow-modules` config parameter.*\n\nThe modules are managed per process role, by default `server` and `master` processes do not load any modules at all to keep them\nsmall and because they monitor workers the less code they have the better.\n\nThe shell process loads all modules, it is configured with `.+`.\n\nTo enable any module to be loaded in any process it can be configured by using a role in the config parameter:\n\n      // Global modules except server and master\n      -allow-modules '.+'\n\n      // Master modules\n      -allow-modules-master 'bk_accounts|bk_debug'\n\nOnce loaded they have the same access to the backend as the rest of the code, the only difference is that they reside in the backend home and\ncan be shipped regardless of the npm, node modules and other env setup. These modules are exposed in the `core.modules` the same way as all other core submodules\nmethods.\n\nLet's assume the modules/ contains file facebook.js which implements custom FB logic:\n\n```javascript\n     var bkjs = require(\"backendjs\");\n     var fb = {\n     }\n     module.exports = fb;\n\n     fb.configureWeb = function(options, callback) {\n       ...\n     }\n\n     fb.makeRequest = function(options, callback) {\n       ...\n     }\n```\n\nThis is the main app code:\n\n```javascript\n    var bkjs = require(\"backendjs\");\n    var core = bkjs.core;\n\n    // Using facebook module in the main app\n    api.app.get(\"some url\", function(req, res) {\n\n       core.modules.facebook.makeRequest({}, function(err, data) {\n          ...\n       });\n    });\n\n    bkj.server.start()\n```\n\n# Database schema definition\n\nThe backend support multiple databases and provides the same db layer for access. Common operations are supported and all other specific usage can be achieved by\nusing SQL directly or other query language supported by any particular database.\nThe database operations supported in the unified way provide simple actions like `db.get, db.put, db.update, db.del, db.select`. The `db.query` method provides generic\naccess to the database driver and executes given query directly by the db driver, it can be SQL or other driver specific query request.\n\nBefore the tables can be queried the schema must be defined and created, the backend db layer provides simple functions to do it:\n\n- first the table needs to be described, this is achieved by creating a Javascript object with properties describing each column, multiple tables can be described\n  at the same time, for example lets define album table and make sure it exists when we run our application:\n\n```javascript\n        db.describeTables({\n           album: {\n               id: { primary: 1 },                         // Primary key for an album\n               name: { pub: 1 },                           // Album name, public column\n               mtime: { type: \"now\" },                     // Modification timestamp\n           },\n           photo: {\n               album_id: { primary: 1 },                   // Combined primary key\n               id: { primary: 1 },                         // consiting of album and photo id\n               name: { pub: 1, index: 1 },                 // Photo name or description, public column with the index for faster search\n               mtime: { type: \"now\" }\n           }\n        });\n```\n\n- the system will automatically create the album and photos tables, this definition must remain in the app source code\n  and be called on every app startup. This allows 1) to see the db schema while working with the app and 2) easily maintain it by adding new columns if\n  necessary, all new columns will be detected and the database tables updated accordingly. And it is all Javascript, no need to learn one more language or syntax\n  to maintain database tables.\n\nEach database may restrict how the schema is defined and used, the db layer does not provide an artificial layer hiding all specifics, it just provides the same\nAPI and syntax, for example, DynamoDB tables must have only hash primary key or combined hash and range key, so when creating table to be used with DynamoDB, only\none or two columns can be marked with primary property while for SQL databases the composite primary key can consist of more than 2 columns.\n\nThe backendjs always creates several tables in the configured database pools by default, these tables are required to support default API functionality and some\nare required for backend opertions. Refer below for the Javascript modules documenttion that described which tables are created by default. In the custom applications\nthe `db.describeTables` method can modify columns in the default table and add more columns if needed.\n\nFor example, to make age and some other columns in the accounts table public and visible by other users with additional columns the following can be\ndone in the `api.initApplication` method. It will extend the bk_account table and the application can use new columns the same way as the already existing columns.\nUsing the birthday column we make 'age' property automatically calculated and visible in the result, this is done by the internal method `api.processAccountRow` which\nis registered as post process callback for the bk_account table. The computed property `age` will be returned because it is not present in the table definition\nand all properties not defined and configured are passed as is.\n\nThe cleanup of the public columns is done by the `api.sendJSON` which is used by all API routes when ready to send data back to the client. If any postprocess\nhooks are registered and return data itself then it is the hook responsibility to cleanup non-public columns.\n\n```javascript\n    db.describeTables({\n        bk_account: {\n            gender: { pub: 1 },\n            birthday: {},\n            ssn: {},\n            salary: { type: \"int\" },\n            occupation: {},\n            home_phone: {},\n            work_phone: {},\n        });\n\n    app.configureWeb = function(options, callback)\n    {\n       db.setProcessRow(\"post\", \"bk_account\", this.processAccountRow);\n       ...\n       callback();\n    }\n    app.processAccountRow = function(req, row, options)\n    {\n       if (row.birthday) row.age = Math.floor((Date.now() - core.toDate(row.birthday))/(86400000*365));\n    }\n```\n\nTo define tables inside a module just provide a `tables` property in the module object, it will be picked up by database initialization automatically.\n\n```javascript\nvar mod = {\n    name: \"billing\",\n    tables: {\n       invoices: {\n          id: { type: \"int\", primary: 1 },\n          name: {},\n          price: { type: \"real\" },\n          mtime: { type: \"now\" }\n       }\n    }\n}\nmodule.exports = mod;\n\n// Run db setup once all the DB pools are configured, for example produce dynamic icon property\n// for each record retrieved\nmod.configureModule = function(options, callback)\n{\n    db.setProcessRows(\"post\", \"invoices\", function(req, row, opts) {\n       if (row.id) row.icon = \"/images/\" + row.id + \".png\";\n    });\n    callback();\n}\n```\n\n# API requests handling\n\nAll methods will put input parameters in the `req.query`, GET or POST.\n\nOne way to verify input values is to use `lib.toParams`, only specified parameters will be returned and converted according to\nthe type or ignored.\n\nExample:\n\n```javascript\n   var params = {\n      test1: { id: { type: \"text\" },\n               count: { type: \"int\" },\n               email: { regexp: /^[^@]+@[^@]+$/ }\n      }\n   };\n\n   api.app.all(\"/endpoint/test1\", function(req, res) {\n      var query = lib.toParams(req.query, params.test1);\n      ...\n   });\n```\n\n# Example of TODO application\n\nHere is an example how to create simple TODO application using any database supported by the backend. It supports basic\noperations like add/update/delete a record, show all records.\n\nCreate a file named `app.js` with the code below.\n\n```javascript\n    var bkjs = require('backendjs');\n    var api = bkjs.api;\n    var lib = bkjs.lib;\n    var app = bkjs.app;\n    var db = bkjs.db;\n\n    // Describe the table to store todo records\n    db.describeTables({\n       todo: {\n           id: { type: \"uuid\", primary: 1 },  // Store unique task id\n           due: {},                           // Due date\n           name: {},                          // Short task name\n           descr: {},                         // Full description\n           mtime: { type: \"now\" }             // Last update time in ms\n       }\n    });\n\n    // API routes\n    app.configureWeb = function(options, callback)\n    {\n        api.app.get(/^\\/todo\\/([a-z]+)$/, function(req, res) {\n           var options = api.getOptions(req);\n           switch (req.params[0]) {\n             case \"get\":\n                if (!req.query.id) return api.sendReply(res, 400, \"id is required\");\n                db.get(\"todo\", { id: req.query.id }, options, function(err, rows) { api.sendJSON(req, err, rows); });\n                break;\n             case \"select\":\n                options.noscan = 0; // Allow empty scan of the whole table if no query is given, disabled by default\n                db.select(\"todo\", req.query, options, function(err, rows) { api.sendJSON(req, err, rows); });\n                break;\n            case \"add\":\n                if (!req.query.name) return api.sendReply(res, 400, \"name is required\");\n                // By default due date is tomorrow\n                if (req.query.due) req.query.due = lib.toDate(req.query.due, Date.now() + 86400000).toISOString();\n                db.add(\"todo\", req.query, options, function(err, rows) { api.sendJSON(req, err, rows); });\n                break;\n            case \"update\":\n                if (!req.query.id) return api.sendReply(res, 400, \"id is required\");\n                db.update(\"todo\", req.query, options, function(err, rows) { api.sendJSON(req, err, rows); });\n                break;\n            case \"del\":\n                if (!req.query.id) return api.sendReply(res, 400, \"id is required\");\n                db.del(\"todo\", { id: req.query.id }, options, function(err, rows) { api.sendJSON(req, err, rows); });\n                break;\n            }\n        });\n        callback();\n     }\n     bkjs.server.start();\n```\n\nNow run it with an option to allow API access without an account:\n\n    node app.js -log debug -web -api-allow-path /todo -db-create-tables\n\nTo use a different database, for example PostgresSQL(running localy) or DynamoDB(assuming EC2 instance),\nall config parametetrs can be stored in the etc/config as well\n\n    node app.js -log debug -web -api-allow-path /todo -db-pool dynamodb -db-dynamodb-pool default -db-create-tables\n    node app.js -log debug -web -api-allow-path /todo -db-pool pgsql -db-pgsql-pool default -db-create-tables\n\nAPI commands can be executed in the browser or using `curl`:\n\n    curl 'http://localhost:8000/todo?name=TestTask1&descr=Descr1&due=2015-01-01`\n    curl 'http://localhost:8000/todo/select'\n\n# Backend directory structure\n\nWhen the backend server starts and no -home argument passed in the command line the backend makes its home environment in the `~/.bkjs` directory.\nIt is also possible to set the default home using BKJS_HOME environment variable.\n\nThe backend directory structure is the following:\n\n* `etc` - configuration directory, all config files are there\n    * `etc/profile` - shell script loaded by the bkjs utility to customize env variables\n    * `etc/config` - config parameters, same as specified in the command line but without leading -, each config parameter per line:\n\n        Example:\n\n            debug=1\n            db-pool=dynamodb\n            db-dynamodb-pool=http://localhost:9000\n            db-pgsql-pool=postgresql://postgres@127.0.0.1/backend\n\n            To specify other config file: bkjs run-backend -config-file file\n\n    * etc/config.local - same as the config but for the cases when local environment is different than the production or for dev specific parameters\n    * some config parameters can be condigured in DNS as TXT records, the backend on startup will try to resolve such records and use the value if not empty.\n      All params that  marked with DNS TXT can be configured in the DNS server for the domain where the backend is running, the config parameter name is\n      concatenated with the domain and queried for the TXT record, for example: `cache-host` parameter will be queried for cache-host.domain.name for TXT record type.\n\n    * `etc/crontab` - jobs to be run with intervals, JSON file with a list of cron jobs objects:\n\n        Example:\n\n        1. Create file in ~/.backend/etc/crontab with the following contents:\n\n                [ { \"cron\": \"0 1 1 * * 1,3\", \"job\": { \"app.cleanSessions\": { \"interval\": 3600000 } } } ]\n\n        2. Define the function that the cron will call with the options specified, callback must be called at the end, create this app.js file\n\n                var bkjs = require(\"backendjs\");\n                bkjs.app.cleanSessions = function(options, callback) {\n                     bkjs.db.delAll(\"session\", { mtime: options.interval + Date.now() }, { ops: \"le\" }, callback);\n                }\n                bkjs.server.start()\n\n        3. Start the jobs queue and the web server at once\n\n                bkjs run-backend -master -web -jobs-workers 1 -jobs-cron\n\n    * etc/crontab.local - additional local crontab that is read after the main one, for local or dev environment\n\n* `modules` - loadable modules with specific functionality\n* `images` - all images to be served by the API server, every subfolder represent naming space with lots of subfolders for images\n* `var` - database files created by the server\n* `tmp` - temporary files\n* `web` - Web pages served by the static Express middleware\n\n# Cache configurations\nDatabase layer support caching of the responses using `db.getCached` call, it retrieves exactly one record from the configured cache, if no record exists it\nwill pull it from the database and on success will store it in the cache before returning to the client. When dealing with cached records, there is a special option\nthat must be passed to all put/update/del database methods in order to clear local cache, so next time the record will be retrieved with new changes from the database\nand refresh the cache, that is `{ cached: true }` can be passed in the options parameter for the db methods that may modify records with cached contents. In any case\nit is required to clear cache manually there is `db.clearCache` method for that.\n\nAlso there is a configuration option `-db-caching` to make any table automatically cached for all requests.\n\n## Local\nIf no cache is configured the local driver is used, it keeps the cache on the master process in the LRU pool and any wroker or Web process\ncommunicate with it via internal messaging provided by the `cluster` module. This works only for a single server.\n\n## memcached\nSet `ipc-cache=memcache://HOST[:PORT]` that points to the host running memcached. To support multiple servrs add the option\n`ipc-cache-options-servers=10.1.1.1,10.2.2.1:5000`.\n\n## Redis\nSet `ipc-cache=redis://HOST[:PORT]` that points to the server running Redis server.\n\nTo support more than one master Redis server in the client add additional servers in the servers parameter,\n`ipc-cache-options-servers=10.1.1.1,10.2.2.1:5000`, the client will reconnect automatically on every\ndisconnect. To support quick failover it needs a parameter for the `node-redis` module (which is used by the driver) `max_attempts` to be a\nnumber how many attempts to reconnect before switching to another server like `ipc-cache-options-max_attempts=3`.\nAny other `node-redis` module parameter can be passed as well.\n\nCache configurations also can be passed in the url, the system supports special parameters that start with `bk-`, it will extract them into options automatically.\n\nFor example:\n\n    ipc-cache=redis://host1?bk-servers=host2,host3&bk-max_attempts=3\n    ipc-cache-backup=redis://host2\n    ipc-cache-backup-options-max_attempts=3\n\n\n## Redis Sentinel\n\nTo enable Redis Sentinel pass in the option `-sentinel-servers`: `ipc-cache=redis://host1?bk-sentinel-servers=host1,host2`.\n\nThe system will connect to the sentinel, get the master cache server and connect the cache driver to it, also it will listen constantly on\nsentinel events and failover to a new master autimatically. Sentinel use the regular redis module and supports all the same\nparameters, to pass options to the sentinel driver prefix them with `sentinel-`:\n\n    ipc-cache=redis://host1?bk-servers=host2,host3&bk-max_attempts=3&bk-sentinel-servers=host1,host2,host3\n    ipc-cache-backup=redis://host2\n    ipc-cache-backup-options-sentinel-servers=host1,host2\n    ipc-cache-backup-options-sentinel-max_attempts=5\n\n\n# PUB/SUB or Queue configurations\n\nPublish/subscribe functionality allows clients to receive notifications without constantly polling for new events. A client can be anything but\nthe backend provides some partially implemented subscription notifications for Web clients using the Long Poll.\nThe Account API call `/account/subscribe` can use any pub/sub mode.\n\nThe flow of the pub/sub operations is the following:\n- a HTTP client makes `/account/subscribe` API request, the connection is made and is kept open indefenitely or as long as configured using `api-subscribe-timeout`.\n- the API backend receives this request, and runs the `api.subscribe` method with the key being the account id, this will subscribe to the events for the current\n  account and registers a callback to be called if any events occured. The HTTP connection is kept open.\n- some other client makes an API call that triggers an event like makes a connectiopn or sends a message, on such event the backend API handler\n  always runs `ipc.publish` after the DB operation succedes. If the messaging is configured, it publishes the message for the account, the\n  message being a JSON object with the request API path and mtime, other properties depend on the call made.\n- the connection that initiated `/account/subscribe` receives an event\n\n## Redis\nTo configure the backend to use Redis for PUB/SUB messaging set `ipc-queue=redis://HOST` where HOST is IP address or hostname of the single Redis server.\nThis will use native PUB/SUB Redis feature.\n\n## Redis Queue\nTo configure the backend to use Redis for job processing set `ipc-queue=redisq://HOST` where HOST is IP address or hostname of the single Redis server.\nThis driver implements reliable Redis queue, with `visibilityTimeout` config option works similar to AWS SQS.\n\nOnce configured, then all calls to `jobs.submitJob` will push jobs to be executed to the Redis queue, starting somewhere a backend master\nprocess with `-jobs-workers 2` will launch 2 worker processes which will start pulling jobs from the queue and execute.\n\nAn example of how to perform jobs in the API routes:\n\n```javascript\n   app.processAccounts = function(options, callback) {\n       db.select(\"bk_account\", { type: options.type || \"user\" }, function(err, rows) {\n          ...\n          callback();\n       });\n   }\n\n   api.all(\"/process/accounts\", function(req, res) {\n       jobs.submitJob({ job: { \"app.processAccounts\": { type: req.query.type } } }, function(err) {\n          api.sendReply(res, err);\n       });\n   });\n\n```\n\n## RabbitMQ\nTo configure the backend to use RabbitMQ for messaging set `ipc-queue=amqp://HOST` and optionally `amqp-options=JSON` with options to the amqp module.\nAdditional objects from the config JSON are used for specific AMQP functions: { queueParams: {}, subscribeParams: {}, publishParams: {} }. These\nwill be passed to the corresponding AMQP methods: `amqp.queue, amqp.queue.sibcribe, amqp.publish`. See AMQP node.js module for more info.\n\n## DB\nThis is a simple queue implementation using the atomic UPDATE, it polls for new jobs in the table and updates the status, only who succeeds\nwith the update takes the job and executes it. It is not effective but can be used for simple and not busy systems for more or less long jobs.\nThe advantage is that it uses the same database and does not require additional servers.\n\n## SQS\nTo use AWS SQS for job processing set `ipc-queue=https://sqs.amazonaws.com....`, this queue system will poll SQS for new messeges on a worker\nand after succsesful execution will delete the message. For long running jobs it will automatically extend visibility timeout if it is configured.\n\n## Local\nThe local queue is implemented on the master process as a list, communication is done via local sockets between the master and workers.\nThis is intended for a single server development pusposes only.\n\n# Security configurations\n\n## API only\nThis is default setup of the backend when all API requests except `/account/add` must provide valid signature and all HTML, Javascript, CSS and image files\nare available to everyone. This mode assumes that Web development will be based on 'single-page' design when only data is requested from the Web server and all\nrendering is done using Javascript. This is how the `api.html` develpers console is implemented, using JQuery-UI and Knockout.js.\n\nTo see current default config parameters run any of the following commands:\n\n        bkjs run-backend -help | grep api-allow\n\n        node -e 'require(\"backendjs\").core.showHelp()'\n\nTo disable open registration in this mode just add config parameter `api-deny-path=^/account/add$` or if developing an application add this in the initMiddleware\n\n        api.initMiddleware = function(callback) {\n            this.allow.splice(this.allow.indexOf('^/account/add$'), 1);\n        }\n\n## Secure Web site, client verification\n\nThis is a mode when the whole Web site is secure by default, even access to the HTML files must be authenticated. In this mode the pages must defined 'Backend.session = true'\nduring the initialization on every html page, it will enable Web sessions for the site and then no need to sign every API reauest.\n\nThe typical client Javascript verification for the html page may look like this, it will redirect to login page if needed,\nthis assumes the default path '/public' still allowed without the signature:\n\n```javascript\n   <script src=\"/js/jquery.js\"></script>\n   <link href=\"/css/bootstrap.css\" rel=\"stylesheet\">\n   <script src=\"/js/bootstrap.js\"></script>\n   <script src=\"/js/knockout.js\" type=\"text/javascript\"></script>\n   <script src=\"/js/crypto.js\" type=\"text/javascript\"></script>\n   <script src=\"/js/bkjs.js\" type=\"text/javascript\"></script>\n   <script src=\"/js/bkjs-bootstrap.js\" type=\"text/javascript\"></script>\n   <script src=\"/js/bkjs-ko.js\" type=\"text/javascript\"></script>\n   <script>\n    $(function () {\n       Bkjs.session = true;\n       $(Bkjs).on(\"nologin\", function() { window.location='/public/index.html'; });\n       Bkjs.koInit();\n   });\n   </script>\n```\n\n## Secure Web site, backend verification\nOn the backend side in your application app.js it needs more secure settings defined i.e. no html except /public will be accessible and\nin case of error will be redirected to the login page by the server. Note, in the login page `Bkjs.session` must be set to true for all\nhtml pages to work after login without singing every API request.\n\n1. We disable all allowed paths to the html and registration:\n\n```javascript\n   app.configureMiddleware = function(options, callback) {\n      this.allow.splice(this.allow.indexOf('^/$'), 1);\n      this.allow.splice(this.allow.indexOf('\\\\.html$'), 1);\n      this.allow.splice(this.allow.indexOf('^/account/add$'), 1);\n      callback();\n   }\n```\n\n2. We define an auth callback in the app and redirect to login if the reauest has no valid signature, we check all html pages, all allowed html pages from the /public\nwill never end up in this callback because it is called after the signature check but allowed pages are served before that:\n\n```javascript\n   api.registerPreProcess('', /^\\/$|\\.html$/, function(req, status, callback) {\n      if (status.status != 200) {\n          status.status = 302;\n          status.url = '/public/index.html';\n      }\n      callback(status);\n   });\n```\n\n# WebSockets connections\n\nThe simplest way is to configure `ws-port` to the same value as the HTTP port. This will run WebSockets server along the regular Web server.\nAll requests must be properly signed with all parameters encoded as for GET requests.\n\nExample:\n\n        wscat --connect ws://localhost:8000\n        connected (press CTRL+C to quit)\n        > /account/get\n        < {\n            \"status\": 400,\n            \"message\": \"Invalid request: no host provided\"\n          }\n        >\n\n# Versioning\n\nThere is no ready to use support for different versions of API at the same because there is no just one solution that satifies all applications. But there are\ntools ready to use that will allow to implement such versioning system in the backend. Some examples are provided below:\n\n- Fixed versions\n  This is similar to AWS version system when versions are fixed and changed not very often. For such cases the backend exposes `core.version` which is\n  supposed to be a core backend version. This version is returned with every backend reponse in the Verison: header. A client also can specify the core version\n  using `bk-version` query parameter or a header. When a request is parsed and the version is provided it will be set in the request options object.\n\n  All API routes are defined using Express middleware and one of the possible ways of dealing with different versions can look like this, by\n  appending version to the command it is very simple to call only changed API code.\n\n```javascript\n          api.all(/\\/domain\\/(get|put|del)/, function(req, res) {\n              var options = api.getOptions(req);\n              var cmd = req.params[0];\n              if (options.appBuild) cmd += \"/\" + options.appBuild;\n              switch (cmd) {\n              case \"get\":\n                  break;\n\n              case \"get/2015-01-01\":\n                  break;\n\n              case \"put\":\n                  break;\n\n              case \"put/2015-02-01\":\n                  break;\n\n              case \"del\"\n                  break;\n              }\n          });\n```\n\n- Application semver support\n  For cases when applications support Semver kind of versioning and it may be too many releases the method above still can be used while the number of versions is\n  small, once too many different versions with different minor/patch numbers, it is easier to support greater/less comparisons.\n\n  The application version `bk-app` can be supplied in the query or as a header or in the user-agent HTTP header which is the easiest case for mobile apps.\n  In the middlware, the code can look like this:\n\n```javascript\n        var options = api.getOptions(req);\n        var version = lib.toVersion(options.appVersion);\n        switch (req.params[0]) {\n        case \"get\":\n            if (version < lib.toVersion(\"1.2.5\")) {\n                res.json({ id: 1, name: \"name\", description: \"descr\" });\n                break;\n            }\n            if (version < lib.toVersion(\"1.1\")) {\n                res.json([id, name]);\n                break;\n            }\n            res.json({ id: 1, name: \"name\", descr: \"descr\" });\n            break;\n        }\n```\n\nThe actual implementation can be modularized, split into functions, controllers.... there are no restrictions how to build the working backend code,\nthe backend just provides all necessary information for the middleware modules.\n\n# The backend provisioning utility: bkjs\n\nThe purpose of the `bkjs` shell script is to act as a helper tool in configuring and managing the backend environment\nand as well to be used in operations on production systems. It is not required for the backend operations and provided as a convenience tool\nwhich is used in the backend development and can be useful for others running or testing the backend.\n\nRunning without arguments will bring help screen with description of all available commands.\n\nThe tool is multi-command utility where the first argument is the command to be executed with optional additional arguments if needed.\nOn Linux, when started the bkjs tries to load and source the following config files:\n\n        /etc/sysconfig/bkjs\n        $BKJS_HOME/etc/profile\n\nAny of the following config files can redefine any environmnt variable thus pointing to the correct backend environment directory or\ncustomize the running environment, these should be regular shell scripts using bash syntax.\n\nMost common used commands are:\n- bkjs run-watcher - run the backend or the app for development purposes, uses local app.js if exists otherwise runs generic server\n- bkjs run-shell - start REPL shell with the backend module loaded and available for use, all submodules are availablein the shell as well like core, db, api\n- bkjs init-app - create the app skeleton\n- bkjs put-backend [-path path] [-host host] [-user user] - sync sources of the app with the remote site, uses BKJS_HOST env variable for host if not specified in the command line, this is for developent version of the backend only\n- bkjs init-server [-home path] [-user user] [-host name] [-domain name] - initialize Linux instance(Amazon,CentOS) for backend use, optional -home can be specified where the backend\n   home will be instead of ~/.bkjs, optional -user tells to use existing user instead of the current user.\n\n   **This command will create `/etc/sysconfig/bkjs` file with BKJS_HOME set to the home of the\n   backendjs app which was pased in the command line. This makes the bkjs or bksh run globally regardless of the current directory.**\n\n# Deployment use cases\n\n## AWS instance setup with node and backendjs\n\nHere is the example how to setup new custom AWS server, it is not required and completely optional but bkjs provies some helpful commands that may simplify\nnew image configuration.\n\n- start new AWS instance via AWS console, use Amazon Linux\n- login as `ec2-user`\n- install commands\n\n        yum-config-manager --enable epel\n        sudo yum install npm\n        npm install backendjs --backendjs_imagemagick\n        sudo bkjs init-service\n        bkjs restart\n\n- try to access the instance via HTTP port 8000 for the API console or documentation\n- after reboot the server will be started automatically\n\n## AWS instance as an appliance\n\nTo make an API appliance by using the backendjs on the AWS instance as user ec2-user with the backend in the user home\n\n- start new AWS instance via AWS console, use Amazon Linux or CentOS 6\n- login as `ec2-user`\n- install commands\n\n        curl -L -o /tmp/bkjs http://bkjs.io/bkjs && chmod 755 /tmp/bkjs\n        /tmp/bkjs install -user ec2-user -prefix ec2-user\n        bkjs restart\n\n- run `ps agx`, it should show several backend processes running\n- try to access the instance via HTTP port for the API console or documentation\n\nNOTE: if running behind a Load balancer and actual IP address is needed set Express option in the command line `-api-express-options {\"trust%20proxy\":1}`. In the config file\nreplacing spaces with %20 is not required.\n\n## AWS Beanstalk deployment\n\nAs with any node.js module, the backendjs app can be packaged into zip file according to AWS docs and deployed the same way as any other node.js app.\nInside the app package etc/config file can be setup for any external connections.\n\n## AWS Provisioning examples\n\nNote: on OS X laptop the `-aws-sdk-profile uc` when AWS credentials are in the ~/.aws/credentials.\n\n### Make an AMI\n\nOn the running machine which will be used for an image:\n\n    bksh -aws-create-image -no-reboot\n\nUse an instance by tag for an image:\n\n    bksh -aws-create-image -no-reboot -instance-id `bkjs show-instances -name api -fmt id | head -1`\n\n### Launch instances when not using AutoScaling Groups\n\nWhen launching from an EC2 instance no need to specify any AWS credentials.\n\n - admin (EC2)\n\n    bksh -aws-sdk-profile uc -aws-launch-instances -aws-instance-type t2.small -subnet-name api -name admin -elb-name Admin -alarm-name alarms -public-ip 1 -dry-run\n\n - api (EC2)\n\n    bksh -aws-sdk-profile uc -aws-launch-instances -aws-instance-type m3.large -subnet-name api -name api -elb-name api -alarm-name alarms -public-ip 1 -dry-run\n\n - jobs (EC2)\n\n    bksh -aws-sdk-profile uc -aws-launch-instances -aws-instance-type t2.small -subnet-name internal -name sync -alarm-name alarms -dry-run\n    bksh -aws-sdk-profile uc -aws-launch-instances -aws-instance-type t2.small -subnet-name internal -name sync -zone 1c -alarm-name alarms -dry-run\n\n - Elasticsearch\n\n    bksh -aws-sdk-profile uc -aws-launch-instances -aws-instance-type m3.large -subnet-name internal -name elasticsearch -bkjs-cmd stop-service -bkjs-cmd \"init-elasticsearch-service -memsize 50\" -alarm-name alarms -public-ip 1 -dry-run\n\n - Redis\n\n    bksh -aws-sdk-profile uc -aws-launch-instances -aws-instance-type m3.large -subnet-name internal -name redis -bkjs-cmd stop-service -bkjs-cmd \"init-redis-service -memsize 70\" -alarm-name alarms -public-ip 1 -dry-run\n\n### Launch Configurations\n\n    bksh -aws-create-launch-config -config-name elasticsearch -aws-sdk-profile uc -instance-type m3.large -update-groups -bkjs-cmd stop-service -bkjs-cmd init-logwatcher -bkjs-cmd \"init-elasticsearch-service -memsize 50\" -device /dev/xvda:gp2:16 -dry-run\n\n### Copy Autoscaling launch configs after new AMI is created\n\n    bksh -aws-create-launch-config -config-name jobs -aws-sdk-profile uc -update-groups -dry-run\n    bksh -aws-create-launch-config -config-name api -aws-sdk-profile uc -update-groups -dry-run\n\n### Update Route53 with all IPs from running instances\n\n    bksh -aws-set-route53 -name elasticsearch.ec-internal -filter elasticsearch\n\n## Proxy mode\n\nBy default the Web proceses spawned by the server are load balanced using default cluster module which relies on the OS to do scheduling. On Linux with node 0.10\nthis is proven not to work properly due to the kernel keeping the context switches to a minimum thus resulting in one process to be very busy while the others\nidle. Node versions 4 and above perform round-robin by default.\n\nFor such case the Backendjs implements the proxy mode by setting `proxy-port` config paremeter to any number above 1000, this will be the initial\nport for the web processes to listen for incoming requests, for example if use `-proxy-port 3000` and launch 2 web processes they will listen on ports\n3000 and 3001. The main server process will start internal HTTP proxy and will perform round-robin load balancing the incoming requests between the web proceses by forwarding\nthem to the web processes over TCP and then returning the responses back to the clients.\n\n## Configure HTTP port\n\nThe first thing when deploying the backend into production is to change API HTTP port, by default is is 8000, but we would want port 80 so regardless\nhow the environment is setup it is ultimatley 2 ways to specify the port for HTTP server to use:\n\n- config file\n\n  The config file is always located in the etc/ folder in the backend home directory, how the home is specified depends on the system but basically it can be\n  defined via command line arguments as `-home` or via environment variables when using bkjs. See bkjs documentation but on AWS instances created with bkjs\n  `init-server` command, for non-standard home use `/etc/sysconfig/bkjs` profile, specify `BKJS_HOME=/home/backend` there and the rest will be taken care of\n\n- command line arguments\n\n  When running node scripts which use the backend, just specify `-home` command line argument with the directory where yor backend should be and the backend will use it\n\n  Example:\n\n        node app.js -home $HOME -port 80\n\n- config database\n\n  If `-db-config` is specified in the command line or `db-config=` in the local config file, this will trigger loading additional\n  config parameters from the specified database pool, it will load all records from the `bk_config` table on that db pool. Using the database to store\n  configuration make it easier to maintain dynamic environment for example in case of auto scaling or lanching on demand, this way\n  a new instance will query current config from the database and this eliminates supporting text files and distributing them to all instances.\n\n  The config database is refreshed from time to time acording to the `db-config-interval` parameter, also all records with `ttl` property in the bk_config\n  will be pulled every ttl interval and updated in place.\n\n- DNS records\n  Some config options may be kept in the DNS TXT records and every time a instance is started it will query the local DNS for such parameters. Only a small subset of\n  all config parameters support DNS store. To see which parmeteres can be stored in the DNS run `bkjs show-help` and look for 'DNS TXT configurable'.\n\n# Backend framework development (Mac OS X, developers)\n\n* for DB drivers and ImageMagick to work propely it needs some dependencies to be installed:\n\n        port install libpng jpeg tiff lcms2 mysql56 postgresql93\n\n* make sure there is no openjpeg15 installed, it will conflict with ImageMagick jp2 codec\n\n* `git clone https://github.com/vseryakov/backendjs.git` or `git clone git@github.com:vseryakov/backendjs.git`\n\n* cd backendjs\n\n* if node.js is already installed skip to the next section\n\n    * to install binary release run the command, it will install it into /opt/local on Darwin\n\n             ./bkjs get-node\n\n             # To install into different path\n             ./bkjs get-node -prefix /usr/local/node\n\n    * node.js can be compiled by the bkjs and installed into default location, on Darwin it is /opt/local\n\n    * to install node.js in $BKJS_PREFIX/bin run command:\n\n            ./bkjs build-node\n\n    * to specify a different install path for the node run\n\n            ./bksj build-node -prefix $HOME\n\n    * **Important**: Add NODE_PATH=$BKJS_PREFIX/lib/node_modules to your environment in .profile or .bash_profile so\n      node can find global modules, replace $BKJS_PREFIX with the actual path unless this variable is also set in the .profile\n\n* to install all dependencies and make backendjs module and bkjs globally available:\n\n            npm link backendjs\n\n* to run local server on port 8000 run command:\n\n            ./bkjs run-backend\n\n* to start the backend in command line mode, the backend environment is prepared and initialized including all database pools.\n   This command line access allows you to test and run all functions from all modules of the backend without running full server\n   similar to node.js REPL functionality. All modules are accessible from the command line.\n\n            $ ./bkjs run-shell\n            > core.version\n            '2013.10.20.0'\n            > logger.setLevel('info')\n\n# Design considerations\n\nWhile creating Backendjs there were many questions and issues to be considered, some i was able to implement, some still not. Below are the thoughts that\nmight be useful when desining, developing or choosing the API platform:\n\n- purpose of the API:\n  - to expose some parts of the existing system to external apps, users...\n  - to make it the only way to access services\n  - to complement another system\n- scalability considerations:\n  - unlimited/uncontrolled access like mobile, web, more users the better\n  - enterprise level, controlled growth\n  - not to be horizontally scalable, just vertically\n- security:\n  - support authentication, users, accounts, profiles...\n  - just for robots, limited by api key only\n  - signed requests only\n  - support all access, web, mobile, desktop\n  - user access controls, how to distinguish users, grant access to only parts of the API\n  - ability to run custom/specific filters during processing API requests, independently and ability to extend the app without rewriting/rebuilding the whole system\n  - third party authentication, OAUTH, user mapping\n- platform/framework:\n  - one for all, same language/SDK/framework to cover all aspects\n  - multiple languages/frameworks for different tasks, then how to integrate, how to communicate, share code\n  - availability of the third party modules, libraries\n  - support, forums, docs, how easy to learn for new developers\n  - modularity, ability to develop by multiple developers, teams\n  - flexibility in extending, how simple/easy to add custom stuff\n  - maintenance, support,how easy to scale, change, replace parts\n- database layer:\n  - one central database for everything\n  - multiple database for different parts of the system according to scalability/other requirements\n  - switch databases behind the scene in order to scale, adding to features, easier to maintain\n  - caching, needs to be independent from other parts and easily enabled/disabled for different components preferably via config\n  - to have or not ORM\n- process management, easy to deploy, monitor\n- logging, metrics, profiling\n- agnostic to the frontends or to be included with some kind of MVC/server based tools\n- ability to support simple Web development for simple web pages without installing/supporting general purpose tools like Apache/PHP/nginx\n\n# API endpoints provided by the backend\n\nAll API endpoints are optional and can be disabled or replaced easily. By default the naming convention is:\n\n     /namespace/command[/subname[/subcommand]]\n\nAny HTTP methods can be used because its the command in the URL that defines the operation. The payload can be urlencoded query\nparameters or JSON or any other format supported by any particular endpoint. This makes the backend universal and usable with any\nenvironment, not just a Web browser. Request signature can be passed in the query so it does not require HTTP headers at all.\n\n## Authentication and sessions\n\n### Signature\n\nAll requests to the API server must be signed with account login/secret pair.\n\n- The algorithm how to sign HTTP requests (Version 1, 2):\n    * Split url to path and query parameters with \"?\"\n    * Split query parameters with \"&\"\n    * '''ignore parameters with empty names'''\n    * '''Sort''' list of parameters alphabetically\n    * Join sorted list of parameters with \"&\"\n        - Make sure all + are encoded as %2B\n    * Form canonical string to be signed as the following:\n        - Line1: The signature version\n        - Line2: The application tag or other opaque data\n        - Line3: The login name\n        - Line4: The HTTP method(GET), followed by a newline.\n        - Line5: The host name, lowercase, followed by a newline.\n        - Line6: The request URI (/), followed by a newline.\n        - Line7: The sorted and joined query parameters as one string, followed by a newline.\n        - Line8: The expiration value in milliseconds, required, followed by a newline\n        - Line9: The Content-Type HTTP header, lowercase, optional, followed by a newline\n        - Line10: The SHA1 checksum of the body content, optional, for JSON and other forms of requests not supported by query paremeters\n    * Computed HMAC-SHA1 digest from the canonical string and encode it as BASE64 string, preserve trailing = if any\n    * Form the signature HTTP header as the following:\n        - The header string consist of multiple fields separated by pipe |\n            - Field1: Signature version:\n                - version 1, obsolete, do not use first 3 lines in the canonical string\n                - version 2,3 to be used in session cookies only\n                - version 4\n            - Field2: Application tag or other app specific data\n            - Field3: account login or whatever it might be in the login column\n            - Field4: HMAC-SHA digest from the canonical string, version 1 uses SHA1, other SHA256\n            - Field5: expiration value in milliseconds, same as in the canonical string\n            - Field6: SHA1 checksum of the body content, optional, for JSON and other forms of requests not supported by query paremeters\n            - Field7: empty, reserved for future use\n\nThe resulting signature is sent as HTTP header `bk-signature` or in the header specified by the `api-signature-name` config parameter.\n\nFor JSON content type, the method must be POST and no query parameters specified, instead everything should be inside the JSON object\nwhich is placed in the body of the request. For additional safety, SHA1 checksum of the JSON paylod can be calculated and passed in the signature,\nthis is the only way to ensure the body is not modified when not using query parameters.\n\nSee [web/js/bkjs.js](https://github.com/vseryakov/backendjs/blob/master/web/js/bkjs.js) function `Bkjs.createSignature` or\n[api.js](https://github.com/vseryakov/backendjs/blob/master/api.js) function `api.createSignature` for the Javascript implementations.\n\nThere is also native iOS implementation [Bkjs.m](https://raw.githubusercontent.com/vseryakov/backendjs-ios/master/BKjs.m).\n\n### Authentication API\n\n- `/auth`\n\n   This API request returns the current user record from the `bk_auth` table if the request is verified and the signature provided\n   is valid. If no signature or it is invalid the result will be an error with the corresponding error code and message.\n\n   By default this endpoint is secured, i.e. requires a valid signature.\n\n   Parameters:\n\n   - `_session=1` - if the call is authenticated a cookie with the session signature is returned, from now on\n      all requests with such cookie will be authenticated, the primary use for this is Web apps\n   - `_accesstoken=1` - returns new access token to be used for subsequent requests without a signature for the current account,\n      the token is short lived with expiration date returned as well. This access token can be used instead of a signature and\n      is passed in the query as `bk-access-token=TOKEN`.\n\n      Example:\n\n              /auth?_accesstoken=1\n              > { id: \"XXXX...\", name: \"Test User\", \"bk-access-token\": \"XXXXX....\", \"bk-access-token-age\": 604800000 }\n\n              /account/get?bk-access-token=XXXXXX...\n              > { id: \"XXXX...\", name: \"Test User\", ... }\n\n- `/login`\n\n   Same as the /auth but it uses cleartext password for user authentication, this request does not need a signature, just simple\n   login and password query parameters to be sent to the backend.\n\n   The intened usage is for Web sessions which use sessions cookies when sent with `_session=1` or to be used with access tokens when\n   sent with `_accesstoken=1`.\n\n   Parameters:\n\n     - `login` - account login\n     - `password` - cleartext password\n     - `_session=1` - same as in /auth request\n     - `_accesstoken=1` - same as in /auth reuest\n\n   On successful login, the result contains full account record including the secret, this is the only time when the secret is returned back\n\n   Example:\n\n              $.ajax({ url: \"/login?login=test123&password=test123&_session=1\",\n                       success: function(json, status, xhr) { console.log(json) }\n              });\n\n              > { id: \"XXXX...\", name: \"Test User\", login: \"test123\", ...}\n\n- `/logout`\n\n   Logout the current user, clear session cookies if exist. For pure API access with the signature this will not do anything on the backend side.\n\n## Accounts\nThe accounts API manages accounts and authentication, it provides basic user account features with common fields like email, name, address.\n\nThis is implemented by the `accounts` module from the core. To enable accounts functionality specify `-allow-modules=bk_accounts`.\n\n- `/account/get`\n\n  Returns information about current account or other accounts, all account columns are returned for the current account and only public columns\n  returned for other accounts. This ensures that no private fields ever be exposed to other API clients. This call also can used to login into the service or\n  verifying if the given login and secret are valid, there is no special login API call because each call must be signed and all calls are stateless and independent.\n\n  Parameters:\n\n    - no id is given, return only one current account record as JSON\n    - id=id,id,... - return information about given account(s), the id parameter can be a single account id or list of ids separated by comma\n    - _session=1 - after successful login setup a session with cookies so the Web app can perform requests without signing every request anymore\n    - _accesstoken=1 - after successful login, return new access token that ca be used to make requests without signing every request, it can be\n       passed in the query or headers with the name `bk-access-token`\n\n  Note: When retrieving current account, all properties will be present including the location, for other accounts only the properties marked as `pub` in the\n  `bk_account` table will be returned.\n\n  Response:\n\n          { \"id\": \"57d07a4e28fc4f33bdca9f6c8e04d6c3\",\n            \"name\": \"Test User\",\n            \"name\": \"Real Name\",\n            \"mtime\": 1391824028,\n            \"latitude\": 34,\n            \"longitude\": -118,\n            \"geohash\": \"9qh1\",\n            \"login\": \"testuser\",\n          }\n\n\n- `/account/add`\n\n  Add new account, all parameters are the columns from the `bk_account` table, required columns are: **name, secret or password, login**.\n\n  By default, this URL is in the list of allowed paths that do not need authentication, this means that anybody can add an account. For the real\n  application this may not be a good choice so the simplest way to disable it to add api-deny-path=^/account/add$ to the config file or\n  specify in the command line. More complex ways to perform registration will require adding pre and.or post callbacks to handle account registration\n  for example with invitation codes....\n\n  In the table `bk_auth`, the column `type` is used to disting","starsCount":3,"created":"2014-04-06T20:45:18.752Z","modified":"2017-07-25T03:06:13.896Z","lastPublisher":{"name":"veryakov","email":"vseryakov@gmail.com"},"owners":[{"name":"veryakov","email":"vseryakov@gmail.com"}],"other":{"_attachments":{},"_from":".","_id":"backendjs","_nodeVersion":"6.11.0","_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/backendjs-0.57.0.tgz_1500951971604_0.3382431324571371"},"_npmUser":{"name":"veryakov","email":"vseryakov@gmail.com"},"_npmVersion":"3.10.10","_rev":"4-4ec168b7781db78fbb7a72915a3ede18","_shasum":"f3bc5a240c0a8d4606e15eb7c84adfdc181de1b2","author":{"name":"Vlad Seryakov"},"bugs":{"url":"https://github.com/vseryakov/backendjs/issues"},"directories":{},"dist-tags":{"latest":"0.57.0"},"dist":{"shasum":"f3bc5a240c0a8d4606e15eb7c84adfdc181de1b2","tarball":"https://registry.npmjs.org/backendjs/-/backendjs-0.57.0.tgz"},"maintainers":[{"name":"veryakov","email":"vseryakov@gmail.com"}],"readmeFilename":"README.md","time":{"modified":"2017-07-25T03:06:13.896Z","created":"2014-04-06T20:45:18.752Z","0.9.0":"2014-04-06T20:45:18.752Z","0.9.1":"2014-04-13T04:51:24.923Z","0.9.2":"2014-04-24T20:16:38.870Z","0.9.3":"2014-04-25T02:26:35.721Z","0.9.4":"2014-04-28T23:00:44.817Z","0.9.5":"2014-05-05T20:04:29.553Z","0.9.6":"2014-05-08T04:45:07.926Z","0.9.7":"2014-05-13T16:51:02.645Z","0.9.8":"2014-05-28T05:33:41.203Z","0.9.9":"2014-06-07T03:25:03.204Z","0.9.10":"2014-06-29T03:49:16.276Z","0.9.11":"2014-07-12T07:33:00.001Z","0.9.13":"2014-09-08T04:43:17.263Z","0.9.15":"2014-10-11T12:36:04.861Z","0.9.16":"2014-10-23T00:32:03.836Z","0.9.17":"2014-11-28T02:29:52.825Z","0.12.0":"2015-03-28T20:53:13.750Z","0.13.0":"2015-05-11T02:37:23.941Z","0.14.1":"2015-07-31T00:56:46.089Z","0.25.1":"2016-03-09T19:25:44.473Z","0.55.0":"2017-04-27T04:13:10.534Z","0.57.0":"2017-07-25T03:06:13.896Z"},"users":{"rebolon":true,"goliatone":true,"dbogda":true}}}